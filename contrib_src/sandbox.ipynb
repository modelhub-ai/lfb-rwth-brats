{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how use the model api to run predictions and get information from the model. You can use it as basis to write your own experiements using the model in this container.\n",
    "\n",
    "To start, import _modelapi.model_, which will give us access to the api of the model in this container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiating U-Net\n",
      "Initiating U-Net no padding\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "from modelapi import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading done\n",
      "affine recovered\n",
      "Sanity check on boxed data:\n",
      "Element has shape (136, 172, 134)\n",
      "Element has shape (136, 172, 134)\n",
      "Element has shape (136, 172, 134)\n",
      "Element has shape (136, 172, 134)\n",
      "Element has shape (136, 172, 134)\n",
      "Element has shape (136, 172, 134)\n",
      "dataset assembled\n",
      "first U-Net running\n",
      "(240, 240, 155)\n",
      "[49, 185, 42, 214, 4, 138]\n",
      "[0, 0, 0, 0, 0, 0]\n",
      "[[ -1.  -0.  -0.   0.]\n",
      " [ -0.  -1.  -0. 239.]\n",
      " [  0.   0.   1.   0.]\n",
      " [  0.   0.   0.   1.]]\n",
      "(5, 136, 176, 136)\n",
      "torch.Size([1, 5, 136, 176, 136])\n",
      "prediction1 is running\n",
      "reshaping predictions\n",
      "preprocessing step 2\n",
      "in loop now\n",
      "reshaping prediction\n",
      "iterating through regions\n",
      "second U-Net running\n",
      "Processing Segmentation...\n"
     ]
    }
   ],
   "source": [
    "result = model.predict('sample_data/sample.json')\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recover prediction from h5 file\n",
    "resultFile = result[\"output\"][0][\"prediction\"].replace(\"api\", \"\")\n",
    "f = h5py.File(resultFile, 'r')\n",
    "print(list(f.keys()))\n",
    "# load the actual prediction and check for correct shape\n",
    "prediction = f[\"Segmentation\"]\n",
    "print('Shape of prediction is: {}'.format(prediction.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(prediction[90], aspect=0.5)\n",
    "print(prediction[90].max(), prediction[90].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ask the model for a list of sample data, then run a prediction on the first of the sample dataset, and then display the prediction result output.\n",
    "\n",
    "If the model does not provide any sample data, print an error message (this part also shows how to read meta info - like the model's name - from the models config)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = model.get_samples()\n",
    "if len(samples[\"files\"]) > 0:\n",
    "    inputFile = samples[\"folder\"] + \"/\" + samples[\"files\"][0]\n",
    "    result = model.predict(inputFile)\n",
    "    for i, output in enumerate(result[\"output\"]):\n",
    "        print(\"\\n\" + result[\"model\"][\"name\"] + \" Output \" + str(i) + \":\")\n",
    "        print(\"  Type:  \" + output[\"type\"])\n",
    "        print(\"  Name:  \" + output[\"name\"])\n",
    "        print(\"  Shape: \" + str(output[\"shape\"]))\n",
    "        print(\"  Prediction:\")\n",
    "        if output[\"type\"] in [\"mask_image\", \"image\"]:\n",
    "            # if output seems to be an image, try displaying it nicely with PIL\n",
    "            try:\n",
    "                import PIL\n",
    "                image = PIL.Image.fromarray(output[\"prediction\"])\n",
    "                display(image)\n",
    "            except:\n",
    "                display(output[\"prediction\"])\n",
    "        else:\n",
    "            display(output[\"prediction\"])\n",
    "else:\n",
    "    model_name = model.get_config()[\"meta\"][\"name\"]\n",
    "    print(model_name + \" does not provide any sample data, please try your own data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
